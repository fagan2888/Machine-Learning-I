{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1 align=\"center\"> \n",
    "DATS 6202, Fall 2018, Exercise_10\n",
    "</h1> \n",
    "\n",
    "<h4 align=\"center\"> \n",
    "Yuxiao Huang ([yuxiaohuang@gwu.edu](mailto:yuxiaohuang@gwu.edu))\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Note\n",
    "- Complete the missing parts indicated by # Implement me\n",
    "- We expect you to follow a reasonable programming style. While we do not mandate a specific style, we require that your code to be neat, clear, **documented/commented** and above all consistent. **Marks will be deducted if these are not followed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some conversion between you and your engineer friend...\n",
    "$\\textbf{Friend}$: Thanks again for solving the XOR problem only using perceptrons! You are really awesome!\n",
    "\n",
    "$\\textbf{You}$: I know.\n",
    "\n",
    "$\\textbf{Friend}$: ... Have you ever worked on Iris?\n",
    "\n",
    "$\\textbf{You}$: Who hasn't?\n",
    "\n",
    "$\\textbf{Friend}$: ... I heard that missing values can cause a lot of troubles.\n",
    "\n",
    "$\\textbf{You}$: Not necessarily. You can still do things with them.\n",
    "\n",
    "$\\textbf{Friend}$: Oh really? What if 90% of the class labels are missing? Can you predict them?\n",
    "\n",
    "$\\textbf{You}$: No.\n",
    "\n",
    "$\\textbf{Friend}$: Well, you know what? Don't feel bad about yourself. You don't have to know everything.\n",
    "\n",
    "$\\textbf{You}$: What I am saying is, I do not even need 10% labels. Remove all the labels if you want and leave only three unique ones. I can give you over 70% prediction accuracy.\n",
    "\n",
    "$\\textbf{Friend}$: Only three labels? Are you serious?\n",
    "\n",
    "$\\textbf{You}$: Positive. The only problem is, I am a data scientist. I do not create missing values on purpose. You do that. Then I will go from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Your friend diligently removed labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Load Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "                 header=None,\n",
    "                 names=['sepal length', 'sepal width', 'petal length', 'petal width', 'target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Get the feature and target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = df[['sepal length', 'sepal width', 'petal length', 'petal width']].values, df['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Encode the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target\n",
    "# Implement me\n",
    "le = LabelEncoder()\n",
    "y = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Divide the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train before removing the class labels:\n",
      "[2 2 2 0 0 0 1 2 1 2 0 1 1 1 0 0 2 1 1 2 2 1 0 0 1 1 0 1 2 2 2 1 2 2 0 0 0\n",
      " 1 0 0 2 1 2 0 0 0 1 1 0 1 1 1 2 0 1 1 1 1 2 0 1 2 1 1 2 1 2 0 1 2 2 2 2 0\n",
      " 2 0 0 2 1 0 0 0 0 0 1 2 2 2 0 2 0 0 1 1 1 1 0 2 2 0 2 1 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n",
    "\n",
    "# Print y_train\n",
    "print('y_train before removing the class labels:')\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Standardize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Implement me\n",
    "X_train = \n",
    "X_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Get the index of rows containing the three unique class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "classes, indices = np.unique(y_train, return_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7. Remove the classes (by chaining them to -1) in rows where the classes have already appeared\n",
    "In the end, y_train contains only three unique class labels. The removed classes are denoted by '-1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train after removing the labels:\n",
      "[ 2 -1 -1  0 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array([y_train[i] if i in indices else -1 for i in range(y_train.shape[0])])\n",
    "\n",
    "# Print y_train\n",
    "print('y_train after removing the labels:')\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Your turn\n",
    "Hint: You are expected to use KMeans to handle this problem. The idea is as follows:\n",
    "1. When applying KMeans on the training data, we get the cluster index for each sample (in the training data), some of which have class labels (that are not -1). Thus we can obtain a map (a dictionary in essence) from cluster index to class.\n",
    "2. When applying KMeans on the testing data, we get the cluster index for each sample (in the testing data). Using the map above, we can obtain the predicted classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. The KMeans model\n",
    "Hint: Consider the number of class labels (in the data) when deciding the value of n_clusters for KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Implement me\n",
    "km = KMeans(n_clusters=, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. On the training data, compute cluster centers and predict cluster indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement me\n",
    "y_train_pred = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Create the map from cluster index to class label (that is not -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_ = {}\n",
    "for i in range(y_train.shape[0]):\n",
    "    if y_train[i] != -1:\n",
    "        # Implement me\n",
    "        key = \n",
    "        # Implement me\n",
    "        val = \n",
    "        # Implement me\n",
    "        dict_[key] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. On the testing data, predict cluster indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement me\n",
    "y_test_pred = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. On the testing data, transform the cluster indices into class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement me\n",
    "y_test_pred = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7555555555555555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "print('Accuracy:', end=' ')\n",
    "print(precision_recall_fscore_support(y_test_pred, y_test, average='micro')[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
