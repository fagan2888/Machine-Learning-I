{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1 align=\"center\"> \n",
    "DATS 6202, Fall 2018, Homework_2\n",
    "</h1> \n",
    "\n",
    "<h4 align=\"center\"> \n",
    "Author: Yuxiao Huang ([yuxiaohuang@gwu.edu](mailto:yuxiaohuang@gwu.edu))\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "- Complete the missing parts indicated by # Implement me\n",
    "- Submit an ipynb file named Homework_2.ipynb to [blackboard](https://blackboard.gwu.edu) folder /Assignments/Homework_2/\n",
    "-  We expect you to follow a reasonable programming style. While we do not mandate a specific style, we require that your code to be neat, clear, **documented/commented** and above all consistent. **Marks will be deducted if these are not followed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- Apply logistic regression on the [Breast Cancer Wisconsin (Diagnostic)](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic%29) and [Car Evaluation](https://archive.ics.uci.edu/ml/datasets/car+evaluation) dataset\n",
    "- There are two goals here:\n",
    "    - Implement two logistic regression models. The first one is heavily based on list (so we call it the slow model), whereas the second largely based on numpy array (so we call it the fast model). Evaluate the two models in terms of their classification accuracy and speed (i.e., run time).\n",
    "    - Apply the logistic regression model implemented by [sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Evaluate the model in terms of its classification accuracy and speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Breast Cancer Wisconsin (Diagnostic) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0             1000025                5                        1   \n",
       "1             1002945                5                        4   \n",
       "2             1015425                3                        1   \n",
       "3             1016277                6                        8   \n",
       "4             1017023                4                        1   \n",
       "\n",
       "   Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                         1                  1                            2   \n",
       "1                         4                  5                            7   \n",
       "2                         1                  1                            2   \n",
       "3                         8                  1                            3   \n",
       "4                         1                  3                            2   \n",
       "\n",
       "  Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  target  \n",
       "0           1                3                1        1       2  \n",
       "1          10                3                2        1       2  \n",
       "2           2                3                1        1       2  \n",
       "3           4                3                7        1       2  \n",
       "4           1                3                1        1       2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data', header=None)\n",
    "df.columns = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove 'Sample code number' (identifier, unique for each sample) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "0                5                        1                         1   \n",
       "1                5                        4                         4   \n",
       "2                3                        1                         1   \n",
       "3                6                        8                         8   \n",
       "4                4                        1                         1   \n",
       "\n",
       "   Marginal Adhesion  Single Epithelial Cell Size Bare Nuclei  \\\n",
       "0                  1                            2           1   \n",
       "1                  5                            7          10   \n",
       "2                  1                            2           2   \n",
       "3                  1                            3           4   \n",
       "4                  3                            2           1   \n",
       "\n",
       "   Bland Chromatin  Normal Nucleoli  Mitoses  target  \n",
       "0                3                1        1       2  \n",
       "1                3                2        1       2  \n",
       "2                3                1        1       2  \n",
       "3                3                7        1       2  \n",
       "4                3                1        1       2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement me\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before removing rows with missing values: 699\n",
      "Number of rows after removing rows with missing values: 683\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('Number of rows before removing rows with missing values: ' + str(df.shape[0]))\n",
    "\n",
    "# Replace ? with np.NaN\n",
    "df.replace('?', np.NaN, inplace=True)\n",
    "\n",
    "# Remove rows with np.NaN\n",
    "# Implement me\n",
    "\n",
    "print('Number of rows after removing rows with missing values: ' + str(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the feature and target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the feature vector\n",
    "# Implement me\n",
    "X = \n",
    "\n",
    "# Get the target vector\n",
    "# Implement me\n",
    "y = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Randomly choose 30% of the data for testing (set randome_state as 0 and stratify as y)\n",
    "# Implement me\n",
    "X_train, X_test, y_train, y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yhuang/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "# Standardize the training data\n",
    "# Implement me\n",
    "X_train = \n",
    "\n",
    "# Standardize the testing data\n",
    "# Implement me\n",
    "X_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My slow logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class MySlowLogisticRegression():\n",
    "    \"\"\"The slow logistic regression classifier (implemented heavily by list)\"\"\"\n",
    "    \n",
    "    def __init__(self, eta=0.01, n_iter=100):\n",
    "        # Initialize the learning rate\n",
    "        self.eta = eta\n",
    "        # Initialize the number of iterations\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        The fit function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        y : the target vector\n",
    "        \"\"\"\n",
    "        \n",
    "        # The dictionary of the weights\n",
    "        self.w_ = {}\n",
    "        # For each class label\n",
    "        for class_ in np.unique(y):\n",
    "            # Initialize the weight for each feature (and the dummy feature, x0)\n",
    "            self.w_[class_] = np.zeros(1 + X.shape[1])\n",
    "\n",
    "        # For each iteration\n",
    "        for _ in range(self.n_iter):\n",
    "            # For each class label\n",
    "            for class_ in self.w_.keys():\n",
    "                # Initialize the update (of the weight) for each feature (and the dummy feature, x0)\n",
    "                delta_w = np.zeros(1 + X.shape[1])\n",
    "\n",
    "                # For each sample\n",
    "                for i in range(X.shape[0]): \n",
    "                    # Get the net_input\n",
    "                    # Implement me\n",
    "                    z = \n",
    "                    \n",
    "                    # Get the logistic sigmoid activation\n",
    "                    # Implement me\n",
    "                    prob = \n",
    "                    \n",
    "                    # Get the error\n",
    "                    # Implement me\n",
    "                    error = \n",
    "                    \n",
    "                    # Get the update (of the weight) for each feature\n",
    "                    for j in range(1, X.shape[1] + 1):\n",
    "                        delta_w[j] += self.eta * error * X[i][j - 1]\n",
    "\n",
    "                    # Get the update (of the weight) for the dummy feature, x0\n",
    "                    delta_w[0] += self.eta * error\n",
    "\n",
    "                # Update the weight for each feature (and the dummy feature, x0)\n",
    "                # Implement me\n",
    "                self.w_[class_] += \n",
    "\n",
    "    def net_input(self, X, class_, i):\n",
    "        \"\"\"\n",
    "        Get the net input\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        class_ : a class label of the target\n",
    "        i : the ith sample\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        The net input\n",
    "       \n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize the weighted sum (i.e., the net input)\n",
    "        weighted_sum = self.w_[class_][0]\n",
    "        \n",
    "        # For each feature\n",
    "        for j in range(1, X.shape[1] + 1):\n",
    "            # Implement me\n",
    "            weighted_sum += \n",
    "\n",
    "        return weighted_sum\n",
    "    \n",
    "    def activation(self, z):\n",
    "        \"\"\"\n",
    "        Get the logistic sigmoid activation\n",
    "        Reference: the function is from the \"Python Machine Learning (2nd edition)\" book code repository and info resource\n",
    "        https://github.com/rasbt/python-machine-learning-book-2nd-edition\n",
    "        \"\"\"\n",
    "        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        The predict function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        The predicted class labels of the target\n",
    "        \"\"\"\n",
    "        \n",
    "        # The predicted class labels\n",
    "        y_pred = []\n",
    "        \n",
    "        # For each sample\n",
    "        for i in range(X.shape[0]):\n",
    "            # The list of [probability, class]\n",
    "            prob_classes = []\n",
    "            \n",
    "            # For each class label\n",
    "            for class_ in self.w_.keys():\n",
    "                # Get the net_input\n",
    "                # Implement me\n",
    "                z = \n",
    "\n",
    "                # Get the logistic sigmoid activation\n",
    "                # Implement me\n",
    "                prob = \n",
    "                \n",
    "                # Update prob_classes\n",
    "                prob_classes.append([prob, class_])\n",
    "                \n",
    "            # Sort prob_classes in descending order of probability\n",
    "            prob_classes = sorted(prob_classes, key=lambda x: x[0], reverse=True)\n",
    "            \n",
    "            # Get the predicted class label (the one with the largest probability)\n",
    "            # Implement me\n",
    "            pred_class = \n",
    "            \n",
    "            # Update y_pred\n",
    "            y_pred.append(pred_class)\n",
    "    \n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        y : the target vector\n",
    "        sample_weight : sample weight (None by default)\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        The mean accuracy\n",
    "        \"\"\"\n",
    "\n",
    "        return accuracy_score(y, self.predict(X), sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the slow logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9609756097560975\n",
      "Run time: 1.591623067855835\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# The start time\n",
    "start = time.time()\n",
    "\n",
    "slow_lr = MySlowLogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "slow_lr.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print('Accuracy: ' + str(slow_lr.score(X_test, y_test)))\n",
    "\n",
    "# The end time\n",
    "end = time.time()\n",
    "\n",
    "# Print the Run time\n",
    "print('Run time: ' + str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My fast logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyFastLogisticRegression():\n",
    "    \"\"\"The fast logistic regression classifier (implemented largely by numpy array)\"\"\"\n",
    "    \n",
    "    def __init__(self, eta=0.01, n_iter=100):\n",
    "        # Initialize the learning rate\n",
    "        self.eta = eta\n",
    "        # Initialize the number of iterations\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        The fit function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        y : the target vector\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get the (unique) class labels\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        # Get the number of (unique) class labels\n",
    "        class_num = len(self.classes_)\n",
    "        \n",
    "        # Encode the target using one-hot-encoding\n",
    "        ys = np.zeros((X.shape[0], class_num))\n",
    "        # For each class label\n",
    "        for j in range(class_num):\n",
    "            ys[np.where(y == self.classes_[j]), j] = 1\n",
    "        \n",
    "        # Initialize the weight for each feature (and the dummy feature, x0)\n",
    "        self.w_ = np.zeros((1 + X.shape[1], class_num))\n",
    "\n",
    "        # For each iteration\n",
    "        for _ in range(self.n_iter):\n",
    "            # Get the net_input\n",
    "            # Implement me\n",
    "            net_input = \n",
    "            \n",
    "            # Get the output\n",
    "            # Implement me\n",
    "            output = \n",
    "            \n",
    "            # Get the errors\n",
    "            # Implement me\n",
    "            errors = \n",
    "            \n",
    "            # Get the update (of the weight) for each feature\n",
    "            self.w_[1:, :] += self.eta * X.T.dot(errors)\n",
    "            \n",
    "            # Get the update (of the weight) for the dummy feature, x0\n",
    "            self.w_[0, :] += self.eta * errors.sum()\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"\n",
    "        Get the net input\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        class_ : a class label of the target\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        The net input\n",
    "       \n",
    "        \"\"\"\n",
    "        \n",
    "        return np.matmul(X, self.w_[1:, :]) + self.w_[0, :]\n",
    "    \n",
    "    def activation(self, z):\n",
    "        \"\"\"\n",
    "        Get the logistic sigmoid activation\n",
    "        Reference: the function is from the \"Python Machine Learning (2nd edition)\" book code repository and info resource\n",
    "        https://github.com/rasbt/python-machine-learning-book-2nd-edition\n",
    "        \"\"\"\n",
    "        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        The predict function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        The predicted class label of the target\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get the net_input\n",
    "        # Implement me\n",
    "        net_input = \n",
    "\n",
    "        # Get the output\n",
    "        # Implement me\n",
    "        output = \n",
    "            \n",
    "        return np.asarray([self.classes_[np.argmax(probs)] for probs in output])\n",
    "    \n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        y : the target vector\n",
    "        sample_weight : sample weight (None by default)\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        The mean accuracy\n",
    "        \"\"\"\n",
    "\n",
    "        return accuracy_score(y, self.predict(X), sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the fast logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9658536585365853\n",
      "Run time: 0.00993204116821289\n"
     ]
    }
   ],
   "source": [
    "# The start time\n",
    "start = time.time()\n",
    "\n",
    "fast_lr = MyFastLogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "fast_lr.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print('Accuracy: ' + str(fast_lr.score(X_test, y_test)))\n",
    "\n",
    "# The end time\n",
    "end = time.time()\n",
    "\n",
    "# Print the Run time\n",
    "print('Run time: ' + str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the logistic regression model implemented in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9609756097560975\n",
      "Run time: 0.1733560562133789\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# The start time\n",
    "start = time.time()\n",
    "\n",
    "sklearn_lr = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "sklearn_lr.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print('Accuracy: ' + str(sklearn_lr.score(X_test, y_test)))\n",
    "\n",
    "# The end time\n",
    "end = time.time()\n",
    "\n",
    "# Print the Run time\n",
    "print('Run time: ' + str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Empirical results on Breast Cancer Wisconsin data show that our fast model has the highest accuracy. Further, while the run time of our fast model is higher than that of the sklearn model, it is lower than that of the slow model. This difference in speed is much more significant when applying the models on a dataset that is just a little bit larger than Breast Cancer Wisconsin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Car Evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety target\n",
       "0  vhigh  vhigh     2       2    small    low  unacc\n",
       "1  vhigh  vhigh     2       2    small    med  unacc\n",
       "2  vhigh  vhigh     2       2    small   high  unacc\n",
       "3  vhigh  vhigh     2       2      med    low  unacc\n",
       "4  vhigh  vhigh     2       2      med    med  unacc"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', header=None)\n",
    "df.columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Get the feature vector\n",
    "# Implement me\n",
    "X = \n",
    "\n",
    "# Encode the feature vector using one-hot-encoding\n",
    "# Implement me\n",
    "X = \n",
    "\n",
    "# Get the target vector\n",
    "# Implement me\n",
    "y = \n",
    "\n",
    "# Encode the target vector\n",
    "# Implement me\n",
    "le = \n",
    "y = \n",
    "\n",
    "# Randomly choose 30% of the data for testing (set randome_state as 0 and stratify as y)\n",
    "# Implement me\n",
    "X_train, X_test, y_train, y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the slow logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8439306358381503\n",
      "Run time: 39.14705276489258\n"
     ]
    }
   ],
   "source": [
    "# The start time\n",
    "start = time.time()\n",
    "\n",
    "slow_lr = MySlowLogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "slow_lr.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print('Accuracy: ' + str(slow_lr.score(X_test, y_test)))\n",
    "\n",
    "# The end time\n",
    "end = time.time()\n",
    "\n",
    "# Print the Run time\n",
    "print('Run time: ' + str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the fast logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.838150289017341\n",
      "Run time: 0.027594804763793945\n"
     ]
    }
   ],
   "source": [
    "# The start time\n",
    "start = time.time()\n",
    "\n",
    "fast_lr = MyFastLogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "fast_lr.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print('Accuracy: ' + str(fast_lr.score(X_test, y_test)))\n",
    "\n",
    "# The end time\n",
    "end = time.time()\n",
    "\n",
    "# Print the Run time\n",
    "print('Run time: ' + str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the logistic regression model implemented in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8516377649325626\n",
      "Run time: 0.006749391555786133\n"
     ]
    }
   ],
   "source": [
    "# The start time\n",
    "start = time.time()\n",
    "\n",
    "sklearn_lr = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "sklearn_lr.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print('Accuracy: ' + str(sklearn_lr.score(X_test, y_test)))\n",
    "\n",
    "# The end time\n",
    "end = time.time()\n",
    "\n",
    "# Print the Run time\n",
    "print('Run time: ' + str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Empirical results on Car Evaluation data show that, our fast model is much faster than the slow one (although the accuracy of the fast in this case is a bit lower). Besides the implementation of logistic regression (and gradient descent), what else you can take away from this homework is the use of numpy array and its vectorized operation (which was used in the implementation of the fast model). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
