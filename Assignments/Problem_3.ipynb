{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1 align=\"center\"> \n",
    "DATS 6202, Fall 2018, Homework_3\n",
    "</h1>\n",
    "\n",
    "<h4 align=\"center\"> \n",
    "Yuxiao Huang ([yuxiaohuang@gwu.edu](mailto:yuxiaohuang@gwu.edu))\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Note\n",
    "- Complete the missing parts indicated by # Implement me\n",
    "- Submit an ipynb file named Homework_3.ipynb to [blackboard](https://blackboard.gwu.edu) folder /Assignments/Homework_3/\n",
    "-  We expect you to follow a reasonable programming style. While we do not mandate a specific style, we require that your code to be neat, clear, **documented/commented** and above all consistent. **Marks will be deducted if these are not followed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Your friend, E (an engineer), wants to simulate an XOR ($\\oplus$) gate. E googled it and found the solution on [wikipedia](https://en.wikipedia.org/wiki/XOR_gate). It turns out that, an XOR gate can be built using two logic AND ($\\wedge$) gates and one logic OR ($\\vee$) gate:\n",
    "\n",
    "$$x_1 \\oplus x_2 = \\big( x_1 \\wedge \\neg x_2 \\big) \\vee \\big( \\neg x_1 \\wedge x_2 \\big).$$\n",
    "    \n",
    "Here, the XOR gate takes as binary input $x_1$ and $x_2$. The input of one AND gate is comprised of $x_1$ and $\\neg x_2$ (the first two items on the righthand side of the equation above), and that of the other AND gate is composed of $\\neg x_1$ and $x_2$ (the last two items in the equation). The output of the two AND gates is the input of the OR gate.\n",
    "\n",
    "Based on the equation above, the original problem (simulating an XOR gate) becomes simulating the AND and OR gates. E realized that this is the time to ask help from you, a data scientist. You looked at the problem and found that the AND and OR gates can be simulated using perceptrons (since both gates generate data that are linearly separable). The only challenge is that, you have not learned how to train a sequence of perceptrons yet (i.e., a Neural network). You looked at the equation above for a while and suddendly had the \"Aha!\" moment. \"It is actually an extremely simple problem because we can train the perceptrons independently!\" you said to E, and started writing a fit function that finds the weights of the three perceptrons. You then went beyond that and wrote a check function that tests whether the weights make sense (so that they can generate the correct output, based on the flow discussed below the equation of XOR). After seeing the perfect evaluation scores, E was convinced that this is the simulation he was looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the XOR_Gate class\n",
    "1. You must use the sklearn Perceptron classifier (as shown below)\n",
    "2. You cannot use any other classifiers, they are not what your friend E wants\n",
    "3. In order to have the same result, set max_iter=100 for the Perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "class XOR_Gate():\n",
    "    \"\"\"The XOR_Gate classifier.\"\"\"\n",
    "      \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the gates dictionary\"\"\"\n",
    "        self.gates = {}\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"The fit function.\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "          Training vectors, where n_samples is the number of samples and\n",
    "          n_features is the number of features.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate data for gates 1 to 3 using function get_X123_y123\n",
    "        # Implement me\n",
    "        X1, y1, X2, y2, X3, y3 = \n",
    "        \n",
    "        # Fit the logic and gate: y1 = (x1) and (not x2)\n",
    "        # Implement me\n",
    "        self.gates[1] = \n",
    "        # Implement me (a fit function)\n",
    "        \n",
    "        # Print the weights of the gate\n",
    "        self.print_weights(1)\n",
    "        \n",
    "        # Fit the logic and gate: y2 = (not x1) and (x2)\n",
    "        # Implement me\n",
    "        self.gates[2] = \n",
    "        # Implement me (a fit function)\n",
    "        \n",
    "        # Print the weights of the gate\n",
    "        self.print_weights(2)\n",
    "        \n",
    "        # Fit the logic or gate: y3 = (y1) or (y2) \n",
    "        # Implement me\n",
    "        self.gates[3] = \n",
    "        # Implement me (a fit function)\n",
    "\n",
    "        # Print the weights of the gate\n",
    "        self.print_weights(3)\n",
    "        \n",
    "    def print_weights(self, i):\n",
    "        \"\"\"Print the weights of gate i.\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        i : integer\n",
    "          The number of the gate\n",
    "       \n",
    "        \"\"\"\n",
    "        \n",
    "        print('------------------------')\n",
    "        print(\"Weights for gate \" + str(i) + ':')\n",
    "        print(\"w0: \" + str(self.gates[i].intercept_))\n",
    "        print(\"w1: \" + str(self.gates[i].coef_[0][0]))\n",
    "        print(\"w2: \" + str(self.gates[i].coef_[0][1]))\n",
    "        print()\n",
    "        \n",
    "    def get_X123_y123(self, X):\n",
    "        \"\"\"Generate data for gates 1 to 3.\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "          Feature vectors, where n_samples is the number of samples and\n",
    "          n_features is the number of features.\n",
    "          \n",
    "        Returns\n",
    "        ------------\n",
    "        The data generated for gates 1 to 3\n",
    "        \"\"\"\n",
    "        \n",
    "        # Data for logic and gate: y1 = (x1) and (not x2)\n",
    "        X1 = np.hstack((X[:, 0].reshape(-1, 1), np.where(X[:, 1], 0, 1).reshape(-1, 1)))\n",
    "        y1 = np.logical_and(X1[:, 0], X1[:, 1])\n",
    "        y1 = np.where(y1, 1, 0)\n",
    "\n",
    "        # Data for logic and gate: y2 = (not x1) and (x2)\n",
    "        X2 = np.hstack((np.where(X[:, 0], 0, 1).reshape(-1, 1), X[:, 1].reshape(-1, 1)))\n",
    "        y2 = np.logical_and(X2[:, 0], X2[:, 1])\n",
    "        y2 = np.where(y2, 1, 0)\n",
    "\n",
    "        # Data for logic or gate: y3 = (y1) or (y2) \n",
    "        X3 = np.hstack((y1.reshape(-1, 1), y2.reshape(-1, 1)))\n",
    "        y3 = np.logical_or(X3[:, 0], X3[:, 1])\n",
    "        y3 = np.where(y3, 1, 0)\n",
    "        \n",
    "        return [X1, y1, X2, y2, X3, y3]\n",
    "        \n",
    "    def check(self, X):\n",
    "        \"\"\"Calculate and print the precision, recall, fscore, and support.\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        X: {array-like}, shape = [n_samples, n_features]\n",
    "          Testing vectors, where n_samples is the number of samples and\n",
    "          n_features is the number of features.\n",
    "          \n",
    "        \"\"\"\n",
    "           \n",
    "        # Generate data for gates 1 to 3 using function get_X123_y123\n",
    "        # Implement me\n",
    "        X1, y1, X2, y2, X3, y3 = \n",
    "        \n",
    "        # Predict the value using the logic and gate: y1 = (x1) and (not x2)\n",
    "        # Implement me (a predict function)\n",
    "        y1_pred = \n",
    "        \n",
    "        # Predict the value using the logic and gate: y2 = (not x1) and (x2)\n",
    "        # Implement me (a predict function)\n",
    "        y2_pred = \n",
    "        \n",
    "        # Predict the value using the logic or gate: y3 = (y1) or (y2) \n",
    "        X3_pred = np.hstack((y1_pred.reshape(-1, 1), y2_pred.reshape(-1, 1)))\n",
    "        # Implement me (a predict function)\n",
    "        y3_pred = \n",
    "        \n",
    "        # Print precision, recall, fscore, and support\n",
    "        print('------------------------')\n",
    "        print('Precision, Recall, Fscore, Supporet: ')\n",
    "        print(precision_recall_fscore_support(y3, y3_pred, average='micro'))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "X = np.random.randint(2, size=(100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Randomly choose 30% of the data for testing\n",
    "X_train, X_test = train_test_split(X, test_size=0.3, random_state=0, stratify=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test the XOR_Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Weights for gate 1:\n",
      "w0: [-3.]\n",
      "w1: 2.0\n",
      "w2: 2.0\n",
      "\n",
      "------------------------\n",
      "Weights for gate 2:\n",
      "w0: [-3.]\n",
      "w1: 2.0\n",
      "w2: 2.0\n",
      "\n",
      "------------------------\n",
      "Weights for gate 3:\n",
      "w0: [-1.]\n",
      "w1: 2.0\n",
      "w2: 2.0\n",
      "\n",
      "------------------------\n",
      "Precision, Recall, Fscore, Supporet: \n",
      "(1.0, 1.0, 1.0, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Declare the XOR_Gate classifier\n",
    "xor_gate = XOR_Gate()\n",
    "\n",
    "# Train the classifier\n",
    "xor_gate.fit(X_train)\n",
    "\n",
    "# Test the classifier\n",
    "xor_gate.check(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
